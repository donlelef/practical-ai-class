{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Interaction\n",
    "In this notebook, we show how to interact with an LLM using the APIs.\n",
    "Different from the other notebooks, the model does not run on our machine, but is accessed by sending requests over the internet.\n",
    "First, we need to install and import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Scezum_wLwpy",
    "outputId": "a5ad2d65-9145-4700-cde7-ebd7939f15c9"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGwbMnmYLoz3"
   },
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Text\n",
    "In order to interact with Gemini, we need an API key. \n",
    "The API key is a secret string that will tell Google who is using the model.\n",
    "Never share or publish your API key, it is like a password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4buj4VpLjPC"
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=\"<your api key here>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpUksFGsMLav",
    "outputId": "a2eabde6-13a7-4268-a289-ea23e0e8bcc2"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Why is the sky blue?\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Pictures\n",
    "As in ChatGPT, we can send pictures and have our questions answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3_vaiA_Nyfq"
   },
   "outputs": [],
   "source": [
    "! wget -q https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/12_-_The_Mystical_King_Cobra_and_Coffee_Forests.jpg/800px-12_-_The_Mystical_King_Cobra_and_Coffee_Forests.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afkxpNk5MjX_",
    "outputId": "9b33fa4a-d565-4f03-cdbf-3a3d30f16d3e"
   },
   "outputs": [],
   "source": [
    "picture = client.files.upload(\n",
    "    file=\"/content/800px-12_-_The_Mystical_King_Cobra_and_Coffee_Forests.jpg\"\n",
    ")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"What is this a picture of?\", picture],\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Interaction\n",
    "Now let's see how to interact with OpenAI's models using their API. The approach is similar to Gemini, but uses a different SDK.\n",
    "First, we need to install and import the OpenAI package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Text\n",
    "To interact with OpenAI, we need an API key from OpenAI.\n",
    "You can get one at https://platform.openai.com/api-keys.\n",
    "Never share or publish your API key, it is like a password.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<your api key here>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(model=\"gpt-5.2\", input=\"Why is the sky blue?\")\n",
    "print(response.output_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
